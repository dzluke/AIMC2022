# Source Separation Methods for Computer-assisted Orchestration
**3rd Conference on AI Music Creativity, 2022**

*Luke Dzwonczyk, Léo Chédin, Alejandro Saldarriaga-Fuertes, Max Sherr, Hélène-Camille Crayencour, and Carmine-Emanuele Cella*

**Abstract:** In this paper, we study the possibility of adding source separation as a pre- processing step to the computer-assisted orchestration process. We first discuss the motivation of this addition and its potential to increase the quality of orchestrations of multi-layered sounds. Second, we select several state-of-the-art models for both music source separation (separation of instruments) and universal sound separation (separation of arbitrary sounds), and compare their effectiveness for the task of orchestration. We assess which methods best suit the needs of orchestration by applying them on our own target sounds, orchestrating the separated outputs, and finally comparing them to the orchestration of the same target without separation. Our experiments show that source separation improves the quality of orchestra- tions, and the more accurate the separation, the better the resulting orchestration. Finally, we compare unsupervised methods to supervised methods for separation, and comment on the effect of training data selection on performance of supervised methods.

To listen to musical examples, visit https://dzluke.github.io/AIMC2022/
